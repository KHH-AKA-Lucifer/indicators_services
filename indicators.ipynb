{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, asyncio, urllib.parse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import asyncpg\n",
    "from dotenv import load_dotenv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81181da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e48e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAL_BUCKETS = int(os.getenv(\"HEAL_BUCKETS\", \"2\"))\n",
    "K_LEN = int(os.getenv(\"K_LEN\", \"9\"))\n",
    "D_LEN = int(os.getenv(\"D_LEN\", \"3\"))\n",
    "CCI_SHORT = int(os.getenv(\"CCI_SHORT\", \"3\"))\n",
    "CCI_LONG  = int(os.getenv(\"CCI_LONG\", \"9\"))\n",
    "SLEEP_SEC = float(os.getenv(\"SLEEP_SEC\", \"5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8244fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dsn() -> str:\n",
    "    \"\"\"\n",
    "    creating a single data base connection source.\n",
    "    \"\"\"\n",
    "    dsn = os.getenv(\"DB_DSN\")\n",
    "    if dsn:\n",
    "        return dsn\n",
    "\n",
    "    host = os.getenv(\"host\")\n",
    "    port = os.getenv(\"port\", \"5432\")\n",
    "    user = os.getenv(\"user\")\n",
    "    pwd  = os.getenv(\"pass\")\n",
    "    db   = os.getenv(\"db\")\n",
    "\n",
    "    if not all([host, user, pwd, db]):\n",
    "        raise RuntimeError(\"DB credentials missing: set DB_DSN or host/user/pass/db in .env\")\n",
    "\n",
    "    user_q = urllib.parse.quote_plus(user)\n",
    "    pwd_q  = urllib.parse.quote_plus(pwd)\n",
    "    return f\"postgresql://{user_q}:{pwd_q}@{host}:{port}/{db}\"\n",
    "\n",
    "DB_DSN = build_dsn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ebcc7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:postgresIntegral%231@localhost:5433/live_prices\n"
     ]
    }
   ],
   "source": [
    "print(DB_DSN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37cc566",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSETS = [\n",
    "    (\"gold\", \"6h\", \"ohlc_data_6hr_bid_xau_usd\",  \"indicators_6hr_bid_xau_usd\", \"6 hours\", \"bucket_6h\"),\n",
    "    (\"gold\",      \"1d\", \"ohlc_data_daily_bid_xau_usd\",   \"indicators_daily_bid_xau_usd\",    \"1 day\",   \"bucket_daily\"),\n",
    "    (\"silver\",    \"6h\", \"ohlc_data_6hr_bid_xag_usd\",     \"indicators_6hr_bid_xag_usd\",      \"6 hours\", \"bucket_6h\"),\n",
    "    (\"silver\",    \"1d\", \"ohlc_data_daily_bid_xag_usd\",   \"indicators_daily_bid_xag_usd\",    \"1 day\",   \"bucket_daily\"),\n",
    "    (\"platinum\",  \"6h\", \"ohlc_data_6hr_bid_xpt_usd\",     \"indicators_6hr_bid_xpt_usd\",      \"6 hours\", \"bucket_6h\"),\n",
    "    (\"platinum\",  \"1d\", \"ohlc_data_daily_bid_xpt_usd\",   \"indicators_daily_bid_xpt_usd\",    \"1 day\",   \"bucket_daily\"),\n",
    "    (\"sgd\",       \"6h\", \"ohlc_data_6hr_bid_usd_sgd\",     \"indicators_6hr_bid_usd_sgd\",      \"6 hours\", \"bucket_6h\"),\n",
    "    (\"sgd\",       \"1d\", \"ohlc_data_daily_bid_usd_sgd\",   \"indicators_daily_bid_usd_sgd\",    \"1 day\",   \"bucket_daily\"),\n",
    "    (\"myr\",       \"6h\", \"ohlc_data_6hr_bid_usd_myr\",     \"indicators_6hr_bid_usd_myr\",      \"6 hours\", \"bucket_6h\"),\n",
    "    (\"myr\",       \"1d\", \"ohlc_data_daily_bid_usd_myr\",   \"indicators_daily_bid_usd_myr\",    \"1 day\",   \"bucket_daily\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0daa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slowD(df: pd.DataFrame, k_period: int = 9, d_period: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"A stochastic function that calculates the Fast %K & Slow %D using EMA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame (Input dataframe containing OHLC data.)\n",
    "    k_period: int, optional (Period to calculate the Fast %K <default is 9>.)\n",
    "    d_period: int, optional (Period to calculate the Slow %D <default is 3>.)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame (DataFrame that contains Fast %K, Fast %D (EMA), and Slow %D (EMA).)\n",
    "    \"\"\"\n",
    "\n",
    "    # find the highest high market price in the k period\n",
    "    df['highest_high'] = df['high'].rolling(window=k_period).max()\n",
    "\n",
    "    # find the lowest low market price in the k period\n",
    "    df['lowest_low'] = df['low'].rolling(window=k_period).min()\n",
    "\n",
    "    # calculate Fast %K\n",
    "    df['fastk'] = ((df['close'] - df['lowest_low']) / (df['highest_high'] - df['lowest_low'])) * 100\n",
    "\n",
    "    # calculate Fast %D (EMA of Fast %K with period 1, which is just FastK itself)\n",
    "    df['fastd'] = df['fastk']\n",
    "\n",
    "    # calculate Slow %D (EMA of Fast %D with period d_period)\n",
    "    df['slowd'] = df['fastd'].ewm(span=d_period, adjust=False).mean()\n",
    "\n",
    "    # drop unecessary columns\n",
    "    df.drop(columns=['highest_high', 'lowest_low'], inplace=True)\n",
    "\n",
    "    # Return the dataframe with stochastic values\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5740bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cci(df: pd.DataFrame, period: int) -> pd.DataFrame:\n",
    "    \"\"\" A method that calculates commodity channel index.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: pd.DataFrame (Input dataframe containing OHLC data.)\n",
    "        period: int (lookback period)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame (DataFrame that contains Commodity Channel Index (CCI).)\n",
    "    \"\"\"\n",
    "        \n",
    "    # calculate the typical price\n",
    "    df['typical_price'] = (df['high'] + df['low'] + df['close']) / 3\n",
    "\n",
    "    # calculate the simple moving average (SMA) of the Typical Price\n",
    "    sma = df['typical_price'].rolling(window=period).mean()\n",
    "\n",
    "    # calculate the mean deviation manually\n",
    "    mean_deviation = df['typical_price'].rolling(window=period).apply(\n",
    "        lambda x: (np.abs(x - x.mean()).mean()), raw=True\n",
    "    )\n",
    "\n",
    "    # calculate the CCI\n",
    "    df[f'CCI{period}'] = (df['typical_price'] - sma) / \\\n",
    "        (0.015 * mean_deviation)\n",
    "\n",
    "    # return the resulted dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150129ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ DB helpers -------------\n",
    "# async def fetch_ca_window(conn, schema: str, \n",
    "#                           ca_table: str, \n",
    "#                           bucket_sql: str, \n",
    "#                           lookback_buckets: int, \n",
    "#                           bucket_col: str) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Pull a compact window from the CA, aliasing bucket_* to 'date_time'.\n",
    "#     bucket_sql is '6 hours' or '1 day'.\n",
    "#     \"\"\"\n",
    "#     sql = f\"\"\"\n",
    "#         SELECT {bucket_col} AS date_time,\n",
    "#                open AS \"Open\", high AS \"High\", low AS \"Low\", close AS \"Close\"\n",
    "#         FROM {schema}.{ca_table}\n",
    "#         WHERE {bucket_col} >= time_bucket($1::interval, now()) - ($2::int + 5) * $1::interval\n",
    "#         ORDER BY {bucket_col}\n",
    "#     \"\"\"\n",
    "#     rows = await conn.fetch(sql, bucket_sql, lookback_buckets)\n",
    "#     if not rows:\n",
    "#         return pd.DataFrame(columns=[\"date_time\",\"Open\",\"High\",\"Low\",\"Close\"])\n",
    "#     # asyncpg Record -> dict list -> DataFrame\n",
    "#     return pd.DataFrame([dict(r) for r in rows])\n",
    "\n",
    "async def fetch_ca_window(conn, schema, ca_table, bucket_sql, lookback_buckets, bucket_col):\n",
    "    sql = f\"\"\"\n",
    "        SELECT {bucket_col} AS date_time,\n",
    "               (open)::double precision  AS open,\n",
    "               (high)::double precision  AS high,\n",
    "               (low)::double precision   AS low,\n",
    "               (close)::double precision AS close\n",
    "        FROM {schema}.{ca_table}\n",
    "        WHERE {bucket_col} >= time_bucket(($1)::text::interval, now())\n",
    "                              - ($2::int + 5) * (($1)::text::interval)\n",
    "        ORDER BY {bucket_col}\n",
    "    \"\"\"\n",
    "    rows = await conn.fetch(sql, bucket_sql, lookback_buckets)\n",
    "    if not rows:\n",
    "        return pd.DataFrame(columns=[\"date_time\",\"open\",\"high\",\"low\",\"close\"])\n",
    "    return pd.DataFrame([dict(r) for r in rows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "748f8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def upsert_indicator_row(conn, schema: str, ind_table: str, dt, slowd, cci3, cci9):\n",
    "    sql = f\"\"\"\n",
    "        INSERT INTO {schema}.{ind_table} (date_time, slowd, cci3, cci9, updated_at)\n",
    "        VALUES ($1, $2, $3, $4, now())\n",
    "        ON CONFLICT (date_time) DO UPDATE SET\n",
    "            slowd = EXCLUDED.slowd,\n",
    "            cci3  = EXCLUDED.cci3,\n",
    "            cci9  = EXCLUDED.cci9,\n",
    "            updated_at = now();\n",
    "    \"\"\"\n",
    "    await conn.execute(sql, dt, slowd, cci3, cci9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23348fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ema_extra_warmup(d_period: int, tol: float = 1e-3) -> int:\n",
    "    # EMA alpha for pandas ewm(span=d, adjust=False)\n",
    "    alpha = 2 / (d_period + 1)\n",
    "    # m such that (1 - alpha)^m <= tol\n",
    "    m = math.log(tol) / math.log(1 - alpha)\n",
    "    return max(0, math.ceil(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f410d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Core per-table work -------------\n",
    "async def process_one_table(conn, schema: str,\n",
    "                            interval_label: str,\n",
    "                            ca_table: str,\n",
    "                            ind_table: str,\n",
    "                            bucket_sql: str,\n",
    "                            bucket_col: str):\n",
    "    # longest = max(K_LEN, CCI_LONG)\n",
    "    # WARMUP = (K_LEN + D_LEN - 1) * 10  # for SlowD\n",
    "    # longest = max(WARMUP, CCI_LONG)\n",
    "    WARMUP_EMA = ema_extra_warmup(D_LEN, tol=1e-3)  # e.g., ~10 for d=3, ~35 for d=10\n",
    "    WARMUP_BASE = K_LEN + (D_LEN - 1)               # %K window plus D seed\n",
    "    longest = max(WARMUP_BASE + WARMUP_EMA, CCI_LONG) + 5  # +5 cushion\n",
    "    df = await fetch_ca_window(conn, schema, ca_table, bucket_sql, longest, bucket_col)\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    # Use time as index\n",
    "    df = df.set_index(\"date_time\")\n",
    "\n",
    "    # Compute using YOUR functions (they may output 'SlowD' and 'CCI{n}')\n",
    "    stoch_df = calculate_slowD(df.copy(), k_period=K_LEN, d_period=D_LEN)\n",
    "    cci3_df  = calculate_cci(df.copy(), period=CCI_SHORT)\n",
    "    cci9_df  = calculate_cci(df.copy(), period=CCI_LONG)\n",
    "\n",
    "    # --- Find columns case-insensitively and normalize names ---\n",
    "    # SlowD\n",
    "    try:\n",
    "        slowd_src = next(c for c in stoch_df.columns if c.lower() == \"slowd\")\n",
    "    except StopIteration:\n",
    "        raise KeyError(\"Stochastic function did not produce a 'SlowD' column\")\n",
    "\n",
    "    # CCIx\n",
    "    want_cci3 = f\"cci{CCI_SHORT}\"\n",
    "    want_cci9 = f\"cci{CCI_LONG}\"\n",
    "    try:\n",
    "        cci3_src = next(c for c in cci3_df.columns if c.lower() == want_cci3)\n",
    "    except StopIteration:\n",
    "        raise KeyError(f\"calculate_cci(period={CCI_SHORT}) did not produce '{want_cci3}' / 'CCI{CCI_SHORT}'\")\n",
    "    try:\n",
    "        cci9_src = next(c for c in cci9_df.columns if c.lower() == want_cci9)\n",
    "    except StopIteration:\n",
    "        raise KeyError(f\"calculate_cci(period={CCI_LONG}) did not produce '{want_cci9}' / 'CCI{CCI_LONG}'\")\n",
    "\n",
    "    # Combine and keep only the columns you store\n",
    "    merged = df.join(stoch_df[[slowd_src]].rename(columns={slowd_src: \"slowd\"}), how=\"left\")\n",
    "    merged = merged.join(cci3_df[[cci3_src]].rename(columns={cci3_src: \"cci3\"}), how=\"left\")\n",
    "    merged = merged.join(cci9_df[[cci9_src]].rename(columns={cci9_src: \"cci9\"}), how=\"left\")\n",
    "\n",
    "    # Forming + small heal window\n",
    "    n = HEAL_BUCKETS + 1\n",
    "    last_idx = merged.index[-n:] if len(merged) >= n else merged.index\n",
    "    trimmed = merged.loc[last_idx, [\"slowd\", \"cci3\", \"cci9\"]].reset_index()  # includes date_time\n",
    "\n",
    "    # Upsert a few rows (forming + previous heal buckets)\n",
    "    for _, row in trimmed.iterrows():\n",
    "        await upsert_indicator_row(\n",
    "            conn, schema, ind_table,\n",
    "            row[\"date_time\"], row[\"slowd\"], row[\"cci3\"], row[\"cci9\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8294f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Main loop -------------\n",
    "async def main():\n",
    "    conn = await asyncpg.connect(dsn=DB_DSN)\n",
    "    try:\n",
    "        while True:\n",
    "            got = await conn.fetchval(\n",
    "                \"SELECT pg_try_advisory_lock( hashtextextended('indicators_service_async', 202) )\"\n",
    "            )\n",
    "            if not got:\n",
    "                await asyncio.sleep(SLEEP_SEC)\n",
    "                continue\n",
    "\n",
    "            tx = conn.transaction()\n",
    "            await tx.start()\n",
    "            try:\n",
    "                for schema, interval_label, ca_table, ind_table, bucket_sql, bucket_col in ASSETS:\n",
    "                    await process_one_table(conn, schema, interval_label, ca_table, ind_table, bucket_sql, bucket_col)\n",
    "                await tx.commit()\n",
    "            except Exception as e:\n",
    "                await tx.rollback()\n",
    "                # ensure the lock is released even on error\n",
    "                await conn.execute(\"SELECT pg_advisory_unlock_all();\")\n",
    "                print(\"ERROR in indicators loop:\", e)\n",
    "                await asyncio.sleep(SLEEP_SEC)\n",
    "                continue\n",
    "            # success path unlock\n",
    "            await conn.execute(\"SELECT pg_advisory_unlock_all();\")\n",
    "            await asyncio.sleep(SLEEP_SEC)\n",
    "    finally:\n",
    "        await conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f873fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31249658",
   "metadata": {},
   "outputs": [],
   "source": [
    "await main()  # will run forever (use Ctrl+Stop to interrupt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
